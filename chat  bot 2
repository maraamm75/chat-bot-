import streamlit as st
import pandas as pd
import numpy as np
import requests
import ollama

MODEL = "llama3.2"


st.title("ðŸ’¬ Chat with Llama 3.2")

x = st.text_input("Favourite movie?")
if st.button("Answer"):
    st.write(f"Your fav movie is: {x}")

try:
    data = pd.read_csv("movie_data_2025.csv")
    st.subheader("Movie Data 2025")
    st.write(data)
except FileNotFoundError:
    st.error("CSV file not found. Please make sure 'movie_data_2025.csv' is in the working directory.")

chart_df = pd.DataFrame(
    np.random.randn(20, 2),
    columns=["Budget_Million_USD", "Box_Office_Million_USD"]
)
st.subheader("Random Budget & Box Office Data")
st.bar_chart(chart_df)
st.line_chart(chart_df)


if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "system", "content": "ðŸ’¬ Chat with llama3.2"}]  
if "full_message" not in st.session_state:
    st.session_state.full_message = ""

for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

def generate_response():

    response = ollama.chat(MODEL, messages=st.session_state.messages, stream=True)
    for chunk in response:
        token = chunk["message"]["content"]
        st.session_state.full_message += token
        yield token

if prompt := st.chat_input("Ask me anythingâ€¦"):
 
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)


    st.session_state.full_message = ""

    with st.chat_message("assistant"):
        response_stream = generate_response()
        st.write_stream(response_stream)

    st.session_state.messages.append({
        "role": "assistant",
        "content": st.session_state.full_message
    })
